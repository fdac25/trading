{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGGbCt4hH12BgN6fEt60o1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fdac25/trading/blob/main/src/LLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pe2OOn8am4ae",
        "outputId": "78a6b8e4-9238-4d81-961b-81863465b17a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# WIP - still converting to fit our application\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "CJ0fftZem9Ki"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df = pd.read_csv('input csv here')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "sbsZgZEonCMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To remove patterns from the text\n",
        "def clean_text(d):\n",
        "    pattern = r'[^a-zA-Z\\s]'\n",
        "    text = re.sub(pattern, '', d)\n",
        "    return text"
      ],
      "metadata": {
        "id": "r0S8Bb_UnGsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this is where we want to put the names of the stocks probably, depending on article\n",
        "names = ['','']"
      ],
      "metadata": {
        "id": "RpEOr3-LnOFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to remove stop words from the text\n",
        "def clean_stopword(d):\n",
        "    stop_words = stopwords.words('english')\n",
        "    for name in names:\n",
        "        stop_words.append(name)\n",
        "    return \" \".join([w.lower() for w in d.split() if w.lower() not in stop_words and len(w) > 1])"
      ],
      "metadata": {
        "id": "xOPLgyPFnXKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To tokenize the text\n",
        "def tokenize(d):\n",
        "    return word_tokenize(d)"
      ],
      "metadata": {
        "id": "GDSzDOwGnaCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying all the functions\n",
        "df['final_text']= df.text.apply(clean_text).apply(clean_stopword).apply(tokenize)\n",
        "df.final_text.head()"
      ],
      "metadata": {
        "id": "iR4q0pRMncZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting tokens to strings\n",
        "for i in range(len(df)):\n",
        "    df['final_text'][i] = \" \".join(df['final_text'][i])"
      ],
      "metadata": {
        "id": "DT9mY2jgngMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding neagtivereason to strings\n",
        "df['final_text_2'] = df['negativereason'].fillna('') + ' ' + df['final_text']\n",
        "df[['final_text' , 'final_text_2']]"
      ],
      "metadata": {
        "id": "m8Qrs65xni4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Picking out X and y from the data\n",
        "X = df.final_text_2\n",
        "y = df.sentiment"
      ],
      "metadata": {
        "id": "vystIqHMnk8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splliting the X and y into training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                   test_size = 0.2, random_state = 4)"
      ],
      "metadata": {
        "id": "3WtEwFB6nzpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "id": "l5POkyo8n2HQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "id": "fmsAY70Vn5u_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test"
      ],
      "metadata": {
        "id": "YAmGjNZCn7GY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "id": "o55DWNuXn9iv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TF-IDF Vectorizer\n",
        "def tfidf(words):\n",
        "    tfidf_vectorizer = TfidfVectorizer()\n",
        "    data_feature = tfidf_vectorizer.fit_transform(words)\n",
        "    return data_feature, tfidf_vectorizer\n",
        "\n",
        "X_train_tfidf, tfidf_vectorizer = tfidf(X_train.tolist())\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test.tolist())"
      ],
      "metadata": {
        "id": "429vrD1Vn_Yx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression Model to predict\n",
        "lr_tfidf = LogisticRegression(random_state=42,solver = 'liblinear')\n",
        "lr_tfidf.fit(X_train_tfidf, y_train)\n",
        "y_predicted_lr = lr_tfidf.predict(X_test_tfidf)"
      ],
      "metadata": {
        "id": "6afdq9SkoDyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to print accuaracy, precision and recall\n",
        "def score_metrics(y_test, y_predicted):\n",
        "    accuracy = accuracy_score(y_test, y_predicted)\n",
        "    precision = precision_score(y_test, y_predicted,average= 'macro')\n",
        "    recall = recall_score(y_test, y_predicted,average='macro')\n",
        "    f1 = f1_score(y_test, y_predicted,average='macro')\n",
        "    print(\"accuracy = %0.3f, precision = %0.3f, recall = %0.3f, f1 = %0.3f\" % (accuracy, precision, recall, f1))"
      ],
      "metadata": {
        "id": "GwDqIc4EoGY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score_metrics(y_test, y_predicted_lr)"
      ],
      "metadata": {
        "id": "5A99MEWCoJBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to plot Confusion Matrix\n",
        "def plot_confusion_matrix(y_test, y_predicted, title='Confusion Matrix'):\n",
        "    cm = confusion_matrix(y_test, y_predicted)\n",
        "    plt.figure(figsize=(8,6))\n",
        "    sns.heatmap(cm,annot=True, fmt='.20g')\n",
        "    plt.title(title)\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "metadata": {
        "id": "J01KJ7p3oLgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(y_test, y_predicted_lr)"
      ],
      "metadata": {
        "id": "TQJSGKpwoNpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = input(\"Enter String : \")\n",
        "t={'text':t}\n",
        "t = pd.DataFrame(t,index=[0])\n",
        "t = tfidf_vectorizer.transform(t.text.tolist())\n",
        "out = lr_tfidf.predict(t)\n",
        "print('Sentiment Value : ',str(out))"
      ],
      "metadata": {
        "id": "RF5RRYVkoPr2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}